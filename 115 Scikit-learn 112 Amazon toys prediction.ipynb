{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa0c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learndataa learndataa learndataa learndataa learndataa learndataa learndataa learndataa learndataa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a202d",
   "metadata": {},
   "source": [
    "##### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b16fd5",
   "metadata": {},
   "source": [
    "# Selling toys on amazon.in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb0c2b7",
   "metadata": {},
   "source": [
    "Objective: \n",
    "   - Create a classifier that can predict if a toy would sell on amazon.in given information such as title, about item, product description etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e37f1",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8787f5",
   "metadata": {},
   "source": [
    "The CSV file is available at the link below:\n",
    "    \n",
    "    - https://github.com/learndataa/datasets/raw/master/df_upload.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59ba21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afb6db1f",
   "metadata": {},
   "source": [
    "# Lets begin !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16554f58",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "092b6842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37eb3641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import neighbors\n",
    "from sklearn import cluster\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90aef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3ac2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set how many columns/rows to view from a DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f31e3e",
   "metadata": {},
   "source": [
    "#### Download stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e057a790",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/erv/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/erv/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download stop words\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Download WordNet (lexical database for English language)\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c75261a",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc49a85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8136, 20)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/erv/Desktop/python/fun_projects/toys/df_upload.csv\", sep='|', encoding='utf-8')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb69495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_cust_rev</th>\n",
       "      <th>sold_by</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>num_rev</th>\n",
       "      <th>L_cm</th>\n",
       "      <th>W_cm</th>\n",
       "      <th>H_cm</th>\n",
       "      <th>wt_gm</th>\n",
       "      <th>days_elapsed</th>\n",
       "      <th>flag__about_item</th>\n",
       "      <th>flag__prod_description</th>\n",
       "      <th>flag__from_mfg</th>\n",
       "      <th>star*num</th>\n",
       "      <th>title_num</th>\n",
       "      <th>about_num</th>\n",
       "      <th>prod_overview_num</th>\n",
       "      <th>cateogry_num</th>\n",
       "      <th>text</th>\n",
       "      <th>star*num_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>GSV TRADE</td>\n",
       "      <td>kids_jewellery</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>FLIPBOAT Trolley Suitcase for Girl's Kid Toy A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>fashion hub for all</td>\n",
       "      <td>kids_jewellery</td>\n",
       "      <td>344.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.9</td>\n",
       "      <td>28</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>ANNA CREATIONSÂ® Girls Kids Cartoon Pretend Pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_cust_rev              sold_by        category   price  num_rev  L_cm  \\\n",
       "0           3.5            GSV TRADE  kids_jewellery  1149.0     18.0  30.0   \n",
       "1           4.1  fashion hub for all  kids_jewellery   344.0     19.0   NaN   \n",
       "\n",
       "   W_cm  H_cm  wt_gm  days_elapsed  flag__about_item  flag__prod_description  \\\n",
       "0  11.0   4.0  350.0          97.0                 1                       1   \n",
       "1   NaN   NaN    NaN           NaN                 1                       0   \n",
       "\n",
       "   flag__from_mfg  star*num  title_num  about_num  prod_overview_num  \\\n",
       "0               0      63.0         22        115                  1   \n",
       "1               0      77.9         28        117                  1   \n",
       "\n",
       "   cateogry_num                                               text  \\\n",
       "0            22  FLIPBOAT Trolley Suitcase for Girl's Kid Toy A...   \n",
       "1            28  ANNA CREATIONSÂ® Girls Kids Cartoon Pretend Pla...   \n",
       "\n",
       "   star*num_cat  \n",
       "0             1  \n",
       "1             1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68311146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['star*num_cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c9c588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(sold_by_list): 2049\n",
      "(8136, 19)\n"
     ]
    }
   ],
   "source": [
    "### Get sold_by list to put them in the stop list to be removed from keywords\n",
    "sold_by_list = [item.split(' ') for item in df['sold_by'].str.lower().unique() if type(item)!=float]\n",
    "sold_by_list = [item for item_list in sold_by_list for item in item_list]\n",
    "sold_by_list = list(set(sold_by_list)) + ['Â®', 'â¢']\n",
    "print('len(sold_by_list):',len(sold_by_list))\n",
    "\n",
    "df = df.drop(['sold_by'], axis=1)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d647b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_cust_rev</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>num_rev</th>\n",
       "      <th>L_cm</th>\n",
       "      <th>W_cm</th>\n",
       "      <th>H_cm</th>\n",
       "      <th>wt_gm</th>\n",
       "      <th>days_elapsed</th>\n",
       "      <th>flag__about_item</th>\n",
       "      <th>flag__prod_description</th>\n",
       "      <th>flag__from_mfg</th>\n",
       "      <th>star*num</th>\n",
       "      <th>title_num</th>\n",
       "      <th>about_num</th>\n",
       "      <th>prod_overview_num</th>\n",
       "      <th>cateogry_num</th>\n",
       "      <th>text</th>\n",
       "      <th>star*num_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>kids_jewellery</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>22</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>FLIPBOAT Trolley Suitcase for Girl's Kid Toy A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1</td>\n",
       "      <td>kids_jewellery</td>\n",
       "      <td>344.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.9</td>\n",
       "      <td>28</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>ANNA CREATIONSÂ® Girls Kids Cartoon Pretend Pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_cust_rev        category   price  num_rev  L_cm  W_cm  H_cm  wt_gm  \\\n",
       "0           3.5  kids_jewellery  1149.0     18.0  30.0  11.0   4.0  350.0   \n",
       "1           4.1  kids_jewellery   344.0     19.0   NaN   NaN   NaN    NaN   \n",
       "\n",
       "   days_elapsed  flag__about_item  flag__prod_description  flag__from_mfg  \\\n",
       "0          97.0                 1                       1               0   \n",
       "1           NaN                 1                       0               0   \n",
       "\n",
       "   star*num  title_num  about_num  prod_overview_num  cateogry_num  \\\n",
       "0      63.0         22        115                  1            22   \n",
       "1      77.9         28        117                  1            28   \n",
       "\n",
       "                                                text  star*num_cat  \n",
       "0  FLIPBOAT Trolley Suitcase for Girl's Kid Toy A...             1  \n",
       "1  ANNA CREATIONSÂ® Girls Kids Cartoon Pretend Pla...             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "779f1fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star*num_cat\n",
       "1    6790\n",
       "2    1346\n",
       "Name: star*num_cat, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['star*num_cat'])['star*num_cat'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1ac2c",
   "metadata": {},
   "source": [
    "### X, y\n",
    "\n",
    "    * 1 if (star*num<2000) else  # will NOT sell\n",
    "    * 2 if (star*num>=2000) else      # should sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa791cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['avg_cust_rev','star*num', 'star*num_cat', 'num_rev'], axis=1)\n",
    "y = df[['star*num_cat']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb6594",
   "metadata": {},
   "source": [
    "### Stratified shuffle split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c6b6c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=5, random_state=0, test_size=0.2,\n",
      "            train_size=None)\n",
      "TRAIN: [3088 2646 7007 ... 3391 5609 4856] TEST: [6119  419 3829 ... 6113  730 3383]\n",
      "TRAIN: [ 973  901 7319 ...  485 3953 1289] TEST: [ 246 7438  911 ... 5757  220 6610]\n",
      "TRAIN: [1009 6780 1810 ... 2878 2583 6184] TEST: [4154 6950  913 ... 1775 6600 3544]\n",
      "TRAIN: [4918 5076 7621 ... 3819 7589 6073] TEST: [7323 3415  952 ... 1977 2936 5144]\n",
      "TRAIN: [1982 2244 1251 ... 2082 3177 6907] TEST: [ 556 3175 3315 ... 5809 1098 3259]\n",
      "\n",
      " (6508, 15) (1628, 15) (6508, 1) (1628, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "star*num_cat\n",
       "1    5431\n",
       "2    1077\n",
       "Name: star*num_cat, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X, y)\n",
    "print(sss)\n",
    "\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "\n",
    "print('\\n', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "pd.concat([X_train, y_train], axis=1).groupby(['star*num_cat'])['star*num_cat'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830e877",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7405846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def prep(txt):\n",
    "    txt = BeautifulSoup(txt).get_text() # remove HTML tags\n",
    "    txt = re.sub(\"[^a-zA-Z]\", \" \", txt) # remove special characters\n",
    "    txt = txt.lower().split() # convert to lowercase and split each word\n",
    "    \n",
    "    stop_w = set(stopwords.words(\"english\")).union(set(sold_by_list)) # use a set for faster searching\n",
    "    \n",
    "    txt = [w for w in txt if not w in stop_w] # Remove stop words\n",
    "    txt = [WordNetLemmatizer().lemmatize(w) for w in txt] # Lemmatization\n",
    "\n",
    "    return (\" \".join(txt)) # Return the words after joining each word separated by space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73bb1e02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Clean all reviews in the train set\n",
    "clean_reviews = []\n",
    "\n",
    "for i in X_train.index.values:\n",
    "    txt = X_train['text'][i]\n",
    "    #print('i:',i, '\\n', txt, '\\n', type(txt), '\\n\\n')\n",
    "    clean_reviews.append(prep(txt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c15cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all reviews in test set\n",
    "test_reviews = []\n",
    "\n",
    "for i in X_test.index.values:\n",
    "    test_reviews.append(prep(X_test['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a22072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assign reviews and labels to conventional variables (X_train, y_train, X_test)\n",
    "X_train_txt = np.stack(clean_reviews)\n",
    "X_test_txt = np.stack(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a74468c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_train.shape: (6508, 1000) , tfidf_test.shape: (1628, 1000)\n"
     ]
    }
   ],
   "source": [
    "max_features = 1000\n",
    "# Use TF-IDF to vectorize\n",
    "tfidf_vec = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=max_features) # Range of tokens into consideration\n",
    "tfidf_vec = tfidf_vec.fit(X_train_txt)\n",
    "\n",
    "tfidf_train = tfidf_vec.transform(X_train_txt)\n",
    "tfidf_test = tfidf_vec.transform(X_test_txt)\n",
    "\n",
    "\n",
    "print('tfidf_train.shape:', tfidf_train.shape, ', tfidf_test.shape:', tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "003a7e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6508, 6) (1628, 6)\n"
     ]
    }
   ],
   "source": [
    "# Scale\n",
    "X_train_num = X_train[['price','days_elapsed','L_cm','W_cm','H_cm','wt_gm']].fillna(-1) #<-- CHECK !!!\n",
    "X_test_num = X_test[['price','days_elapsed','L_cm','W_cm','H_cm','wt_gm']].fillna(-1)  #<-- CHECK !!!\n",
    "\n",
    "scl = preprocessing.StandardScaler()\n",
    "scl.fit(X_train_num)\n",
    "\n",
    "X_train_num = scl.transform(X_train_num)\n",
    "X_test_num = scl.transform(X_test_num)\n",
    "\n",
    "print(X_train_num.shape, X_test_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d66d1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize category\n",
    "X_train_bin = pd.get_dummies(X_train[['category']], prefix=['cat'], columns = ['category'], drop_first=True)\n",
    "X_test_bin = pd.get_dummies(X_test[['category']], prefix=['cat'], columns = ['category'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3381fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6508, 1016) (1628, 1016)\n"
     ]
    }
   ],
   "source": [
    "# Combine txt and num \n",
    "X_train_final = np.hstack([X_train_num, tfidf_train.toarray(), X_train_bin.to_numpy()]) #, X_train[theme_col_list].to_numpy()])\n",
    "X_test_final  = np.hstack([X_test_num, tfidf_test.toarray(), X_test_bin.to_numpy()]) #, X_test[theme_col_list].to_numpy()])\n",
    "\n",
    "print(X_train_final.shape, X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e961737",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy().ravel()\n",
    "y_test = y_test.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0fb1a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "      <th>L_cm</th>\n",
       "      <th>W_cm</th>\n",
       "      <th>H_cm</th>\n",
       "      <th>wt_gm</th>\n",
       "      <th>days_elapsed</th>\n",
       "      <th>flag__about_item</th>\n",
       "      <th>flag__prod_description</th>\n",
       "      <th>flag__from_mfg</th>\n",
       "      <th>title_num</th>\n",
       "      <th>about_num</th>\n",
       "      <th>prod_overview_num</th>\n",
       "      <th>cateogry_num</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>kids_jewellery</td>\n",
       "      <td>1449.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>22.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>710.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>VikriDa Girl's 2 in 1 Cosmetic and Real Makeup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3175</th>\n",
       "      <td>soft_toys</td>\n",
       "      <td>349.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>Urban Hub Cute Stuffed Cartoon Character Super...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category   price  L_cm  W_cm  H_cm  wt_gm  days_elapsed  \\\n",
       "556   kids_jewellery  1449.0  29.7  22.8  10.2  710.0        1212.0   \n",
       "3175       soft_toys   349.0  17.0  12.0  12.0  452.0         239.0   \n",
       "\n",
       "      flag__about_item  flag__prod_description  flag__from_mfg  title_num  \\\n",
       "556                  1                       1               0         20   \n",
       "3175                 1                       1               0         20   \n",
       "\n",
       "      about_num  prod_overview_num  cateogry_num  \\\n",
       "556         228                  1            20   \n",
       "3175         71                 14            20   \n",
       "\n",
       "                                                   text  \n",
       "556   VikriDa Girl's 2 in 1 Cosmetic and Real Makeup...  \n",
       "3175  Urban Hub Cute Stuffed Cartoon Character Super...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a57b8",
   "metadata": {},
   "source": [
    "### Balance dataset: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a76a29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f326d60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: (6508, 1016) (6508,)\n",
      "Type: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "AFTER: (10862, 1016) (10862,)\n"
     ]
    }
   ],
   "source": [
    "print(\"BEFORE:\", X_train_final.shape, y_train.shape)\n",
    "\n",
    "X_train_s, y_train_s = SMOTE().fit_resample(X_train_final, y_train)\n",
    "\n",
    "print(\"Type:\", type(X_train_final), type(y_train))\n",
    "print(\"AFTER:\", X_train_s.shape, y_train_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc86201",
   "metadata": {},
   "source": [
    "### Logistic Regression WITH SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8162c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf, max_features: 1000\n",
      "score (with SMOTE): 0.8501228501228502\n",
      "score (without SMOTE): 0.8832923832923832\n"
     ]
    }
   ],
   "source": [
    "print('tfidf, max_features:', max_features)\n",
    "\n",
    "# WITH SMOTE\n",
    "clf = LogisticRegression(max_iter=1e4)\n",
    "clf.fit(X_train_s, y_train_s)\n",
    "s = clf.score(X_test_final, y_test)\n",
    "print('score (with SMOTE):', s)\n",
    "\n",
    "# WITHOUT SMOTE\n",
    "clf = LogisticRegression(max_iter=1e4)\n",
    "clf.fit(X_train_final, y_train)\n",
    "s = clf.score(X_test_final, y_test)\n",
    "print('score (without SMOTE):', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af940384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53c711c0",
   "metadata": {},
   "source": [
    "### Gradient boost  WITH SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70864a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afb05ec0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf, max_features: 1000\n",
      "score (with SMOTE): 0.9121621621621622\n",
      "score (without SMOTE): 0.9207616707616708\n"
     ]
    }
   ],
   "source": [
    "print('tfidf, max_features:', max_features)\n",
    "\n",
    "# WITH SMOTE\n",
    "clf = GradientBoostingClassifier(n_estimators=200, random_state=0)\n",
    "clf.fit(X_train_s, y_train_s)\n",
    "s = clf.score(X_test_final, y_test)\n",
    "print('score (with SMOTE):', s)\n",
    "\n",
    "# WITHOUT SMOTE\n",
    "clf = GradientBoostingClassifier(n_estimators=200, random_state=0)\n",
    "clf.fit(X_train_final, y_train)\n",
    "s = clf.score(X_test_final, y_test)\n",
    "print('score (without SMOTE):', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6f0e1",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50a8432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(max_iter=1e4),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    GradientBoostingClassifier(),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    ExtraTreeClassifier()\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27d8bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000.0) : 0.8777398111995557\n",
      "--------------------------------------------------\n",
      "KNeighborsClassifier(n_neighbors=3) : 0.8633777387177214\n",
      "--------------------------------------------------\n",
      "SVC(C=0.025, kernel='linear') : 0.7844782049462848\n",
      "--------------------------------------------------\n",
      "SVC(C=1, gamma=2) : 0.9802068504625412\n",
      "--------------------------------------------------\n",
      "GaussianProcessClassifier(kernel=1**2 * RBF(length_scale=1)) : 0.9675020076767251\n",
      "--------------------------------------------------\n",
      "GradientBoostingClassifier() : 0.910700395635649\n",
      "--------------------------------------------------\n",
      "DecisionTreeClassifier(max_depth=5) : 0.8032595566175008\n",
      "--------------------------------------------------\n",
      "RandomForestClassifier(max_depth=5, max_features=1, n_estimators=10) : 0.6972045104193209\n",
      "--------------------------------------------------\n",
      "MLPClassifier(alpha=1, max_iter=1000) : 0.87258446864337\n",
      "--------------------------------------------------\n",
      "AdaBoostClassifier() : 0.8638395933685382\n",
      "--------------------------------------------------\n",
      "GaussianNB() : 0.7909230379569149\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuadraticDiscriminantAnalysis() : 0.9965937901630707\n",
      "--------------------------------------------------\n",
      "ExtraTreeClassifier() : 0.8955078392210775\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    clf.fit(X_train_s, y_train_s)\n",
    "    clfcv = cross_val_score(clf, X_train_s, y_train_s, cv=3, scoring='accuracy')\n",
    "    \n",
    "    print(clf, \":\", np.mean(clfcv))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46bc58a",
   "metadata": {},
   "source": [
    "### Grid search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8f3a282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'newton-cg'}\n",
      "0.8843727392709079\n"
     ]
    }
   ],
   "source": [
    "parameters = {'solver':('newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga')\n",
    "             }\n",
    "\n",
    "model = LogisticRegression(max_iter = 1e4)\n",
    "clf = GridSearchCV(model, parameters, scoring='accuracy', cv=10)\n",
    "clf.fit(X_train_s, y_train_s)\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053598bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a154c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db054a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0caca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learndataa learndataa learndataa learndataa learndataa learndataa learndataa learndataa learndataa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
